{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791077c5-fad7-4c24-9db4-5907ed15b234",
   "metadata": {},
   "source": [
    "# DARWIN Notebook Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc51e2ac-e902-4f9d-bafc-8bcd53953c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datascience import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0561a8-48ef-48ce-9803-cf11e99ff661",
   "metadata": {},
   "source": [
    "# About this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04d63d5-bbc3-4860-9120-2906161c052c",
   "metadata": {},
   "source": [
    "This notebook assignment uses the DARWIN(Diagnosis AlzheimeR WIth haNdwriting) dataset from the UC Irvine Machine Learning Repository. It is a novel dataset containing handwriting data for the prediction of Alzheimer's Disease via handwriting analysis. The dataset contains data from 174 participants: 89 AD patients and 85 healthy people.\n",
    "Participants were recruited using standard clinical tests, namely, Mini-Mental State Examination (MMSE), Frontal Assessment Battery (FAB), and Montreal Cognitive Assessment (MoCA). These tests use questionnaires to assess cognitive skills covering many areas, ranging from orientation in time and place to registration recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368531f3-6ac1-49fb-8c2e-3d87c4cd9f4a",
   "metadata": {},
   "source": [
    "The 25 tasks used to collect handwriting data could be grouped as the following: Graphic tasks, which tested participant’s ability in writing elementary traits; they include joining some points and drawing geometrical figures; Copy tasks, which evaluated participant’s abilities in repeating complex graphic gestures, which have semantic meaning such as letters, words and numbers; Memory tasks, which tested the changes in writing process previously memorized or associated with objects shown in a picture, and Dictation tasks, which investigated how handwriting varies when the working memory is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49de57-6d8a-4edb-b956-ecd7a9342fe8",
   "metadata": {},
   "source": [
    "# Interpreting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f84f0-2995-475b-ae29-6fc8a5b5bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data into a Pandas dataframe below\n",
    "\n",
    "darwin_table = ...\n",
    "darwin_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3229e-b4ac-4841-9b0c-b12dece4a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find some summary statistics for this dataset\n",
    "...\n",
    "\n",
    "#look for null values\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630b8c9-b89a-444d-b161-fb552055a9f5",
   "metadata": {},
   "source": [
    "1. What is the mean for 'airtime1'?\n",
    "2. What are the minimum values for 'max_x_extension1' and 'max_y_extension1'?\n",
    "3. Which column has the greatest standard deviation?\n",
    "4. Are there missing values in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b25f68-317f-4603-87b5-73127805aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out some information about this dataframe\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82046887-8d89-4365-858e-febd9f1f8354",
   "metadata": {},
   "source": [
    "1. What are the dimensions of this dataframe?\n",
    "2. Which datatypes are included in this dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df24e0-6ebd-40a6-9527-e3f3560abcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 'class' column consists of labels for each individual's handwriting data\n",
    "darwin_table[\"class\"]\n",
    "\n",
    "#replace 'P' with Patient and 'H' with Healthy\n",
    "darwin_table...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6e04b-8d81-42f9-a2d9-4a3f66024ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the number of healthy people in the dataset\n",
    "darwin_table['class']...\n",
    "\n",
    "number_healthy = ...\n",
    "#find the number of patients(with Alzheimer's)\n",
    "number_w_alz = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2370f-1514-4e57-89a9-e3e0c47812b6",
   "metadata": {},
   "source": [
    "# Visual Representations of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf84b29-9e79-4714-9a22-8e16079940a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select features with strong correlations to visualize data\n",
    "\n",
    "#start off with all the features for the 1st task (column indecies 1-19)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa7e697-7825-46f3-bc97-00d840dbcdc1",
   "metadata": {},
   "source": [
    "Correlation is a measure of the linear relationship of 2 or more variables. Through correlation, we can predict one variable from the other. The logic behind using correlation for feature selection is that the good variables are highly correlated with the target. Furthermore, variables should be correlated with the target but should be uncorrelated among themselves.\n",
    "\n",
    "If two variables are correlated, we can predict one from the other. Therefore, if two features are correlated, the model only really needs one of them, as the second one does not add additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f22c4f77-b1c7-49f4-8f24-25603baecd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a correlation matrix\n",
    "cor_task1 = darwin_table...\n",
    "print(cor_task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53adc2a-43ee-4feb-bf52-cea31ae42316",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cor_task1 > abs(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490188b8-6cd7-4446-9718-ea2d95fafb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting heatmap\n",
    "plt.figure(figsize = (100,20))\n",
    "sns.heatmap(cor, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a800ae-58bd-4fa3-aabe-b7e0dd152848",
   "metadata": {},
   "source": [
    "1. Which features have the strongest correlation values(positive or negative)?\n",
    "2. Create at least 2 scatterplots comparing features with strong correlations. Why is this not the best visualization method? (switch to numpy for creating scatterplots, if you do not have spyder 5.1.5 and pycodestyle>=2.8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800964c5-9e0a-42a5-b63a-7c76ea8e813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#air time and total time(one option)\n",
    "x = np_darwin_table.where('class', are.equal_to('H')).column('air_time1')\n",
    "y = np_darwin_table.where('class', are.equal_to('H')).column('total_time1')\n",
    "\n",
    "plt.scatter(x, y, color = 'hotpink')\n",
    "\n",
    "\n",
    "x = np_darwin_table.where('class', are.equal_to('P')).column('air_time1')\n",
    "y = np_darwin_table.where('class', are.equal_to('P')).column('total_time1')\n",
    "\n",
    "plt.scatter(x, y, color = '#88c999')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4ac6b-0d6c-4fad-b899-0d4233e94778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose own features\n",
    "x = np_darwin_table.where('class', are.equal_to('H')).column(...)\n",
    "y = np_darwin_table.where('class', are.equal_to('H')).column(...)\n",
    "\n",
    "plt.scatter(x, y, color = 'hotpink')\n",
    "\n",
    "\n",
    "x = np_darwin_table.where('class', are.equal_to('P')).column(...)\n",
    "y = np_darwin_table.where('class', are.equal_to('P')).column(...)\n",
    "\n",
    "plt.scatter(x, y, color = '#88c999')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf627c2-0557-4e9b-be3f-d7b8f6068729",
   "metadata": {},
   "source": [
    "# Using Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa485be1-26ea-455d-b357-ee57b97055b2",
   "metadata": {},
   "source": [
    "Information gain calculates the reduction in entropy from the transformation of a dataset. It can be used for feature selection by evaluating the Information gain of each variable in the context of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3652c2c0-0913-4908-980e-2db4a53c9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84c37a-98d1-4b70-a677-d0f0d9bc3100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare features and target variables \n",
    "#use just task 1\n",
    "X_task1 = ... #FEATURES\n",
    "Y_task1 = ... #TARGET\n",
    "\n",
    "print(X_task1)\n",
    "print(Y_task1)\n",
    "\n",
    "importances = mutual_info_classif(X_task1, Y_task1)\n",
    "feat_importances = pd.Series(importances, darwin_table.columns[1:19])\n",
    "print(feat_importances)\n",
    "\n",
    "feat_importances.plot(kind='barh', color='teal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19837636-d8d8-4841-bd0d-35acbc811d7d",
   "metadata": {},
   "source": [
    "1. Which features result in the most information gain?\n",
    "2. Use the two features that result in the most information gain to create a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbedb176-d884-4d4e-b72a-4a61ada90e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f2bda-a5d3-45df-a307-9dfa32e32dd7",
   "metadata": {},
   "source": [
    "Now, select the three most significant features for the first task, and create a 3D scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "002dcb0c-5d43-4344-917d-a448710970bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make 3D scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e70b8-4994-40cf-bf64-7f8c14f5b8e6",
   "metadata": {},
   "source": [
    "Rotate the visualization. Does it make a difference? Which orientation of the features results in the best visualization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0f34f-c5db-4569-80be-ca347fe2acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
